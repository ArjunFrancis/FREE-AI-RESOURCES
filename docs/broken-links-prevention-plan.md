# üîß Broken Links Prevention & Validation Plan

**Effective Date:** December 16, 2025  
**Status:** Active Implementation  
**Priority:** Critical (Quality Assurance)

---

## üéØ Executive Summary

This plan establishes a comprehensive, systematic approach to prevent, detect, and fix broken links in the FREE-AI-RESOURCES repository. The goal is to maintain **99.5%+ link availability** through automated validation, proactive monitoring, and rapid response protocols.

---

## üö® Problem Statement

**Issues Identified:**
- Random link checks revealed 404 errors in multiple categories
- No systematic weekly quality validation
- Lack of automated link checking infrastructure
- No backup URLs for critical resources
- Missing last-verified dates on resources

**Impact:**
- Degraded user experience
- Reduced repository credibility
- Loss of valuable historical resources
- Decreased discoverability and SEO ranking

---

## üìã Multi-Tiered Validation Strategy

### **Tier 1: Pre-Addition Validation** (100% Coverage)
‚úÖ **MANDATORY** before any resource is added to the repository

**Checklist for Every New Resource:**
```markdown
- [ ] HTTP 200 status verified (using curl or browser)
- [ ] Page loads completely (not just domain active)
- [ ] Content matches description (actual resource, not 404/redirect)
- [ ] No paywall/authentication required
- [ ] SSL certificate valid (HTTPS preferred)
- [ ] Archive.org snapshot created (for backup)
- [ ] Add verification date: [Verified: YYYY-MM-DD]
```

**Implementation:**
- Use browser DevTools Network tab to check status codes
- Test with private/incognito window (no cached content)
- Verify from 2+ geographic locations if possible
- Document validation in commit message

---

### **Tier 2: Weekly Automated Validation** (Random Sampling)
ü§ñ **Automated GitHub Action** runs every Monday 6:00 AM UTC

**Scope:**
- Randomly sample **25% of all links** weekly (full coverage monthly)
- Prioritize categories with most resources
- Check HTTP status codes (200, 301, 302 acceptable; 404, 503 fail)
- Generate validation report with failures

**Technology Stack:**
```yaml
- Tool: GitHub Actions + Python script
- Libraries: requests, BeautifulSoup4, link-checker
- Schedule: Weekly (Mondays 6:00 AM UTC)
- Report: Auto-create GitHub Issue for failures
```

**Sample GitHub Action Workflow:**
```yaml
name: Weekly Link Validation

on:
  schedule:
    - cron: '0 6 * * 1'  # Every Monday 6 AM UTC
  workflow_dispatch:      # Manual trigger option

jobs:
  validate-links:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 markdown lxml
      
      - name: Run link validator
        run: python scripts/validate_links.py --sample 25
      
      - name: Create issue if failures
        if: failure()
        uses: actions/create-issue@v2
        with:
          title: "üö® Broken Links Detected - Week ${{ github.run_number }}"
          body-path: validation_report.md
          labels: broken-links,quality,urgent
```

---

### **Tier 3: Monthly Deep Audit** (100% Coverage)
üîç **Comprehensive manual + automated review** on 1st of each month

**Scope:**
- **100% link validation** across all categories
- Content relevance verification (page still matches description)
- Update difficulty tags if needed (üü¢üü°üî¥)
- Check for better/updated resources
- Verify authority sources still operational
- Update "Last Updated" dates

**Protocol:**
1. Run automated validator on ALL links (100% coverage)
2. Manual review of top 10% most popular resources
3. Replace dead links with Archive.org versions OR find alternatives
4. Update resource descriptions if content changed
5. Document changes in monthly audit report

**Audit Report Template:**
```markdown
# Monthly Link Audit Report - [Month Year]

**Date:** YYYY-MM-DD
**Auditor:** [Name/Bot]

## Summary
- Total Links Checked: XXX
- Passed: XXX (XX%)
- Failed (404): XX
- Redirects (301/302): XX
- Updated: XX
- Removed: XX

## Actions Taken
1. Fixed [Resource Name] - replaced URL with archive.org
2. Updated [Resource Name] - new official domain
3. Removed [Resource Name] - permanently unavailable

## High-Priority Fixes Needed
- [ ] Category X: 3 dead links
- [ ] Category Y: authority source changed domain

**Next Audit:** [Date]
```

---

### **Tier 4: Quarterly Authority Verification** (Trust Validation)
üèõÔ∏è **Every 3 months** verify authority sources are still reputable

**Focus:**
- Universities (Stanford, MIT, CMU) - domain changes?
- Official documentation sites (PyTorch, TensorFlow) - structure changes?
- GitHub repos - still actively maintained?
- Course platforms (Coursera, edX) - course still available?

---

## üõ†Ô∏è Implementation Blueprint

### **Phase 1: Immediate Actions** (Week 1 - Dec 16-22, 2025)

**Step 1:** Create validation script
```bash
# File: scripts/validate_links.py
# Purpose: Extract and validate all markdown links
# Features: HTTP status check, timeout handling, retry logic
```

**Step 2:** Manual emergency audit
- Check all 25+ categories for obvious 404s
- Fix critical broken links immediately
- Add [Verified: 2025-12-16] tags to working links

**Step 3:** Create Archive.org backups
- Submit top 50 most critical resources to Wayback Machine
- Add archive URLs as fallback in markdown comments

**Step 4:** Update all category files with verification dates
```markdown
**Last Link Validation:** December 16, 2025  
**Next Scheduled Validation:** January 6, 2026
```

---

### **Phase 2: Automation Setup** (Week 2-3 - Dec 23-Jan 5, 2026)

**Step 1:** Develop Python validation script
```python
# Key Features:
# - Parse all .md files in /resources
# - Extract URLs using regex
# - Check HTTP status with timeout
# - Handle redirects intelligently
# - Generate JSON/Markdown report
# - Create GitHub Issues for failures
```

**Step 2:** Set up GitHub Actions workflow
- Weekly automated validation (25% sampling)
- Monthly full validation (100% coverage)
- Auto-create issues for failures
- Comment on issues when fixed

**Step 3:** Create broken link triage labels
```
Labels to create:
- broken-link-404 (red)
- broken-link-redirect (yellow)
- link-validation (blue)
- quality-check (purple)
- urgent-fix (red)
```

---

### **Phase 3: Process Documentation** (Week 4 - Jan 6-12, 2026)

**Step 1:** Update CONTRIBUTING.md with link validation requirements

**Step 2:** Create link validation badge in README
```markdown
![Link Health](https://img.shields.io/badge/link_health-99.5%25-brightgreen)
**Last Validated:** 2025-12-16
```

**Step 3:** Add pre-commit checklist to PR template
```markdown
## Link Quality Checklist (Required)
- [ ] All new links return HTTP 200
- [ ] No paywalls/authentication required
- [ ] Archive.org backup created for critical resources
- [ ] Verification date added [Verified: YYYY-MM-DD]
```

---

## üìä Quality Metrics & Monitoring

### **Key Performance Indicators (KPIs)**

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Link Availability | ‚â•99.5% | TBD | üü° Measuring |
| Average Response Time | <3s | TBD | üü° Measuring |
| Time to Fix (404s) | <48h | TBD | üü° Measuring |
| Archive Coverage (Top 100) | 100% | TBD | üî¥ Not Started |
| Monthly Audit Completion | 100% | TBD | üî¥ Not Started |

### **Dashboard (To Build)**
- Real-time link health status per category
- Historical trend of link failures
- Top 10 most frequently failing domains
- Archive.org coverage percentage

---

## üö® Incident Response Protocol

### **When Broken Link Detected**

**Priority 1: Critical Resources** (Stanford/MIT courses, official docs)
- **Response Time:** <24 hours
- **Action:** 
  1. Check Archive.org for snapshot
  2. Search for official mirror/updated URL
  3. If unfixable, find equivalent high-quality replacement
  4. Update immediately

**Priority 2: Popular Resources** (GitHub repos, tutorials)
- **Response Time:** <48 hours
- **Action:**
  1. Verify link is actually dead (not temporary outage)
  2. Check GitHub repo moved or renamed
  3. Update URL or replace resource
  4. Add verification note

**Priority 3: Supplementary Resources**
- **Response Time:** <7 days
- **Action:**
  1. Assess continued relevance
  2. Remove if no replacement found
  3. Update category resource count

---

## üîÑ Backup & Recovery Strategy

### **Archive.org Integration**

**For All New Resources:**
```bash
# Automatically submit to Wayback Machine
curl -X POST https://web.archive.org/save/[RESOURCE_URL]
```

**Markdown Comment Format:**
```markdown
- [Resource Name](https://original-url.com) ‚Äì Description
  <!-- Archive: https://web.archive.org/web/20251216/https://original-url.com -->
```

**Priority for Archiving:**
1. University courses (Stanford, MIT, CMU)
2. Official documentation
3. Unique/irreplaceable content
4. Popular tutorials with 1000+ engagements

---

## üìÖ Recurring Tasks Calendar

| Frequency | Task | Day | Owner |
|-----------|------|-----|-------|
| **Daily** | Monitor GitHub Issues for link reports | Weekdays | Maintainer |
| **Weekly** | Automated 25% link validation | Monday 6AM | Bot |
| **Bi-weekly** | Review validation reports | Friday | Maintainer |
| **Monthly** | 100% comprehensive link audit | 1st of month | Team |
| **Quarterly** | Authority source verification | 1st week | Team |
| **Yearly** | Full content relevance review | January | Team |

---

## üéì Training & Documentation

### **For Contributors:**
1. **Required Reading:** 
   - This document (broken-links-prevention-plan.md)
   - Link validation section in CONTRIBUTING.md
   - llm.txt quality standards

2. **Link Validation Tutorial:**
   - Video: "How to Validate Links Before Adding" (TODO: Create)
   - Quick guide: 3-step verification process
   - Tools recommended: curl, httpie, browser DevTools

---

## üîß Technical Specifications

### **Python Link Validator Script**

**Requirements:**
```txt
requests>=2.31.0
beautifulsoup4>=4.12.0
markdown>=3.5.0
pyyaml>=6.0.0
```

**Key Functions:**
```python
def extract_links_from_markdown(file_path: str) -> list[str]
def validate_url(url: str, timeout: int = 10) -> dict
def check_archive_availability(url: str) -> bool
def create_github_issue(failed_links: list) -> None
def generate_report(results: dict) -> str
```

**Error Handling:**
- Retry failed requests 3x with exponential backoff
- Handle timeouts gracefully (mark as "timeout" not "404")
- Detect 403 vs 404 (403 may be temporary/regional block)
- Log all responses for debugging

---

## ‚úÖ Success Criteria

**Short-term (3 months):**
- ‚úÖ All existing links validated at least once
- ‚úÖ Automated validation system operational
- ‚úÖ Zero critical 404 errors (P1 resources)
- ‚úÖ Archive coverage >80% for top 100 resources
- ‚úÖ Link health badge live in README

**Long-term (12 months):**
- ‚úÖ 99.5%+ link availability maintained
- ‚úÖ Automated fixes for common issues (redirects)
- ‚úÖ Community reporting system active
- ‚úÖ Zero broken links reported by users in Issues
- ‚úÖ Industry recognition for quality standards

---

## üìû Escalation & Support

**Reporting Broken Links:**
- **Users:** Create GitHub Issue with label `broken-link`
- **Contributors:** Fix immediately if possible, else escalate
- **Maintainers:** Triage within 24 hours

**Templates:**
```markdown
## Broken Link Report

**Resource:** [Name and URL]
**Category:** [e.g., NLP, Computer Vision]
**Error:** [404, timeout, paywall, etc.]
**Date Discovered:** YYYY-MM-DD
**Suggested Fix:** [If known]

---
Auto-generated by Link Validator v1.0
```

---

## üìà Continuous Improvement

**Quarterly Review Questions:**
1. Are validation intervals appropriate? (Weekly sufficient?)
2. Any recurring domains with failures? (Blocklist?)
3. New validation techniques available? (AI-based content verification?)
4. Community feedback on link quality?
5. Performance metrics meeting targets?

**Improvement Ideas for 2026:**
- AI-powered content similarity check (ensure page content matches description)
- Automated replacement suggestion (find similar resources)
- Browser-based validation (JavaScript-heavy sites)
- Geographic redundancy checks (CDN issues)
- Integration with Link Health APIs

---

## üîí Version Control

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-12-16 | AI Manager | Initial comprehensive plan created |

---

## üìö References & Resources

- [W3C Link Checker](https://validator.w3.org/checklink)
- [Archive.org Save Page API](https://docs.google.com/document/d/1Nsv52MvSjbLb2PCpHlat0gkzw0EvtSgpKHu4mk0MnrA/)
- [GitHub Actions for Link Checking](https://github.com/marketplace/actions/link-checker)
- [HTTP Status Codes Reference](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)

---

**Approved By:** Repository Maintainers  
**Effective Date:** December 16, 2025  
**Next Review:** March 16, 2026

---

## üéØ TL;DR - Quick Action Guide

**For Maintainers:**
1. Run weekly automated validator ‚Üí Fix P1 issues within 24h
2. Monthly deep audit ‚Üí Update all categories
3. Monitor GitHub Issues ‚Üí Respond to community reports

**For Contributors:**
1. Validate every link before PR (HTTP 200 check)
2. Add [Verified: DATE] to new resources
3. Create Archive.org snapshot for critical resources
4. Include validation in PR checklist

**For Users:**
1. Report broken links via GitHub Issues
2. Use provided templates
3. Suggest replacement resources if known

---

*This is a living document. Suggest improvements via PR or Issues.*

**Repository:** github.com/ArjunFrancis/FREE-AI-RESOURCES  
**Document Path:** /docs/broken-links-prevention-plan.md