# ğŸµ Audio & Speech Processing

Speech recognition (ASR), text-to-speech (TTS), audio analysis, voice synthesis, and speech understanding using machine learning and signal processing techniques.

## ğŸ“– Overview

Audio and speech processing enables machines to understand, generate, and analyze human speech and audio signals. This field combines digital signal processing, linguistics, and deep learning to power applications like voice assistants, transcription services, translation systems, and audio generation tools. From automatic speech recognition to voice cloning, this category covers the full spectrum of speech AI technologies.

**Keywords:** audio-processing, speech-recognition, asr, automatic-speech-recognition, text-to-speech, tts, speech-synthesis, voice-processing, speech-datasets, audio-analysis, voice-assistant, transcription, whisper, wav2vec

**Skill Levels:** ğŸŸ¢ Beginner | ğŸŸ¡ Intermediate | ğŸ”´ Advanced

---

## ğŸ“š Topics Covered

- Automatic Speech Recognition (ASR)
- Text-to-Speech (TTS) synthesis
- Speech-to-text transcription
- Voice activity detection (VAD)
- Speaker recognition and verification
- Emotion recognition from speech
- Audio signal processing fundamentals
- Speech enhancement and denoising
- Multilingual speech processing
- Voice cloning and synthesis
- Audio feature extraction (MFCCs, spectrograms)
- End-to-end neural speech models
- Real-time speech processing
- Speech synthesis agents and emotional TTS
- Foundation models for speech and audio

---

## â­ Starter Kit (Absolute Beginners Start Here)

**If you're completely new to Audio & Speech Processing, start with these 3 resources in order:**

1. ğŸŸ¢ [Digital Speech Processing Course (Rutgers)](https://www.mathworks.com/academia/courseware/digital-speech-processing.html) - Start here for fundamental principles of speech processing, acoustics, and digital signal processing with MATLAB examples.
2. ğŸŸ¢ [Common Voice by Mozilla](https://commonvoice.mozilla.org/en/datasets) - Next step: Explore the largest open speech dataset to understand real-world speech data across 100+ languages.
3. ğŸŸ¡ [OpenAI Whisper Documentation](https://github.com/openai/whisper) - Advance to state-of-the-art speech recognition with production-ready model you can run locally.

**After completing the starter kit, explore the full resources below.**

---

## ğŸ“Š Open Speech Datasets

### ğŸŸ¢ Beginner-Friendly

- [Common Voice by Mozilla](https://commonvoice.mozilla.org/en/datasets) â€“ The world's largest open-source multilingual speech dataset with 30,000+ hours across 100+ languages. Crowdsourced from volunteers worldwide, ideal for training diverse speech recognition models with varied accents, ages, and speech patterns. Completely free and openly licensed. (ğŸŸ¢ Beginner)
  - ğŸ“– Access: Fully open, CC0 license
  - ğŸ›ï¸ Authority: Mozilla Foundation
  - ğŸ“œ Features: 100+ languages, metadata (age/gender/accent)
  - ğŸ’¾ Size: 30,000+ hours
  - [Tags: speech-dataset multilingual open-source mozilla crowdsourced 2025]

- [LibriSpeech](http://www.openslr.org/12/) â€“ High-quality English speech dataset derived from audiobooks with 1,000 hours of read speech at 16kHz. Widely used benchmark for ASR with clean recordings, accurate transcriptions, and standardized train/dev/test splits. The gold standard for English speech recognition research. (ğŸŸ¢ Beginner to ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully open, free download
  - ğŸ›ï¸ Authority: OpenSLR (widely cited)
  - ğŸ“œ Features: Well-annotated, phonetic transcriptions
  - ğŸ’¾ Size: 1,000 hours English
  - [Tags: librispeech audiobooks english asr-benchmark clean-audio 2025]

- [VoxForge](http://www.voxforge.org/) â€“ Open-source project collecting transcribed speech for acoustic model training across multiple languages. Community-contributed dataset ideal for multilingual speech recognition projects and learning ASR fundamentals with real volunteer recordings. (ğŸŸ¢ Beginner)
  - ğŸ“– Access: Fully open, GPL license
  - ğŸ“œ Features: Multilingual, community-driven
  - ğŸ›ï¸ Authority: Open-source community
  - [Tags: voxforge multilingual community open-source transcribed-speech 2025]

### ğŸŸ¡ Intermediate

- [OpenSLR (Open Speech and Language Resources)](https://www.openslr.org/resources.php) â€“ Comprehensive collection of free speech and language datasets including multilingual corpora, TTS datasets, ASR benchmarks, and specialized audio collections. Features datasets like Multilingual LibriSpeech, AISHELL (Mandarin), MediaSpeech, and 50+ other resources. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully open, various licenses
  - ğŸ›ï¸ Authority: Community repository
  - ğŸ“œ Features: 50+ datasets, multiple languages
  - ğŸ’¾ Size: Varies by dataset
  - [Tags: openslr multilingual dataset-collection asr tts comprehensive 2025]

- [TED-LIUM](https://www.openslr.org/51/) â€“ High-quality English speech corpus derived from TED Talks with 450+ hours covering diverse topics and speakers from around the world. Features professional audio quality, varied speaking styles, and rich vocabulary making it excellent for robust ASR training. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully open, free download
  - ğŸ›ï¸ Authority: LIUM (University of Le Mans)
  - ğŸ“œ Features: Diverse topics, global speakers
  - ğŸ’¾ Size: 450+ hours English
  - [Tags: ted-lium ted-talks diverse-speakers english asr-dataset 2025]

- [SpeechOcean](https://www.speechocean.com/datasets/) â€“ Free academic speech datasets including multilingual data, labeled audio files, and pronunciation scoring datasets. Valuable for research projects needing diverse linguistic data with professional annotations and quality labels. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Free for academic use
  - ğŸ›ï¸ Authority: SpeechOcean Technology
  - ğŸ“œ Features: Multilingual, pronunciation labels
  - âš ï¸ Note: Academic license
  - [Tags: speechocean multilingual pronunciation academic-research labeled-audio 2025]

---

## ğŸ“ Courses & Educational Resources

### ğŸŸ¢ Beginner

- [Digital Speech Processing (Rutgers University)](https://www.mathworks.com/academia/courseware/digital-speech-processing.html) â€“ Comprehensive free course covering basic principles of digital speech processing including acoustics of speech generation, perceptual criteria, speech analysis, synthesis algorithms, and applications. Includes lectures, assignments, MATLAB files, and 60+ DSP apps for hands-on learning. (ğŸŸ¢ Beginner to ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully open, complete courseware
  - ğŸ›ï¸ Authority: Rutgers University (Professor Lawrence Rabiner)
  - ğŸ› ï¸ Hands-on: MATLAB apps + assignments
  - ğŸ“œ Features: Syllabus, lectures, projects
  - [Tags: course rutgers speech-processing dsp matlab fundamentals 2025]

- [LearnOpenCV: Introduction to Speech to Speech](https://learnopencv.com/speech-to-speech/) â€“ Free comprehensive tutorial covering complete speech-to-speech pipeline for building voice assistants. Explains Voice Activity Detection (VAD), Speech-to-Text (STT), Language Models, and Text-to-Speech (TTS) with practical code examples using Whisper, Hugging Face models, and Python. Beginner-friendly with detailed component explanations and inference demonstrations. (ğŸŸ¢ Beginner to ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully free, blog format
  - ğŸ›ï¸ Authority: LearnOpenCV (industry expert)
  - ğŸ› ï¸ Hands-on: Complete Python implementation
  - ğŸ“œ Components: VAD, STT, LLM, TTS pipeline
  - [Tags: beginner tutorial speech-to-speech voice-assistant pipeline end-to-end 2025]

### ğŸŸ¡ Intermediate

- [Stanford CS224S: Spoken Language Processing](https://web.stanford.edu/class/cs224s/) â€“ Comprehensive university course on modern spoken language technology covering speech recognition (ASR), text-to-speech synthesis (TTS), dialogue systems, and neural approaches. Features lectures, assignments, projects using Python/PyTorch, and recorded video content. Taught by Stanford faculty with industry expertise. Spring 2025 offering with latest techniques. (ğŸŸ¡ Intermediate to ğŸ”´ Advanced)
  - ğŸ“– Access: Fully free, complete course materials
  - ğŸ›ï¸ Authority: Stanford University (official course 2025)
  - ğŸ› ï¸ Hands-on: Python/PyTorch projects and assignments
  - ğŸ“œ Features: Video lectures, slides, homeworks
  - ğŸ“º Format: Recorded lectures available online
  - [Tags: stanford cs224s spoken-language university-course asr tts python pytorch 2025]

- [Speech and Language Processing (Jurafsky & Martin, 3rd Edition)](https://web.stanford.edu/~jurafsky/slp3/) â€“ Comprehensive free online textbook covering speech and language processing with chapters on phonetics, speech feature extraction (Ch. 14), automatic speech recognition (Ch. 15), and text-to-speech synthesis (Ch. 16). Includes lecture slides for all chapters and is regularly updated with latest techniques and research. (ğŸŸ¡ Intermediate to ğŸ”´ Advanced)
  - ğŸ“– Access: Fully free, complete textbook online
  - ğŸ›ï¸ Authority: Stanford University (Jurafsky & Martin)
  - ğŸ“œ Features: 16 chapters + appendices, slides for each chapter
  - ğŸ“š Coverage: ASR, TTS, linguistic fundamentals, LLMs
  - [Tags: textbook jurafsky-martin stanford slp3 speech-processing comprehensive 2025]

### ğŸ”´ Advanced

- [Speech and Audio Foundation Models TTIC 2025](https://sites.google.com/view/speech-ai-ttic-2025/schedule-talks) **(Advanced)** - Advanced workshop on spoken language models and audio foundation models from Toyota Technological Institute at Chicago (TTIC). Covers latest research in speech foundation models, audio understanding, multilingual ASR (120+ languages), voice AI agents, Audio Flamingo 3, and emerging 2025 trends. Speakers include leading researchers from Meta AI, Apple, UT Austin, and major tech companies. Perfect for advanced practitioners staying current with state-of-the-art. (ğŸ”´ Advanced)
  - ğŸ“– Access: Fully free, workshop materials and talks
  - ğŸ›ï¸ Authority: TTIC (leading AI research institution)
  - ğŸ› ï¸ Focus: Foundation models, spoken language models, audio AI
  - ğŸ“œ Topics: ASR 120+ languages, TTS, voice agents, Audio Flamingo 3
  - ğŸ“ Speakers: Meta, Apple, UT Austin researchers
  - [Tags: advanced ttic workshop foundation-models spoken-language-models audio-ai 2025]

- [Deep Dive into Speech Synthesis Agents (2025)](https://sparkco.ai/blog/deep-dive-into-2025-speech-synthesis-agents) â€“ Comprehensive guide exploring modern speech synthesis agents with focus on emotional intelligence, multilingual support, personalization, and real-time synthesis. Covers architecture, implementation best practices, integration with LangChain/LangGraph frameworks, and emerging 2025 trends including voice cloning, emotion control, and commerce integration. Perfect for advanced developers building next-gen voice AI. (ğŸ”´ Advanced)
  - ğŸ“– Access: Fully free, detailed technical guide
  - ğŸ›ï¸ Authority: Sparkco AI (2025 industry analysis)
  - ğŸ› ï¸ Hands-on: Code examples with LangChain/LangGraph
  - ğŸ“œ Topics: Emotional TTS, personalization, multilingual, real-time synthesis
  - ğŸ”§ Frameworks: LangChain, LangGraph, AutoGen
  - [Tags: advanced speech-synthesis agents emotional-ai 2025 langchain implementation]

---

## ğŸ”¬ Guides & Comparative Analysis

### ğŸŸ¡ Intermediate

- [Top 8 Open Source STT Options for Voice Applications 2025](https://assemblyai.com/blog/top-open-source-stt-options-for-voice-applications) **(Intermediate)** - Comprehensive comparative guide of open-source speech-to-text engines for 2025. Analyzes Whisper (99 languages), Wav2Vec2 (multilingual), SpeechT5, NeMo, Kaldi, PocketSphinx, and emerging models. Covers Word Error Rate (WER) performance metrics, strengths/limitations, language support, and use case recommendations. Essential for choosing the right STT engine for your project. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully free, detailed comparison guide
  - ğŸ›ï¸ Authority: AssemblyAI (industry leader)
  - ğŸ“œ Coverage: 8+ open-source STT options
  - ğŸ““ Metrics: WER performance, language support, features
  - ğŸ¯ Purpose: Model selection, use case matching
  - [Tags: intermediate stt-comparison open-source whisper wav2vec 2025]

- [Automatic Speech Recognition in 2025: How ASR Works](https://graphlogic.ai/blog/ai-chatbots/ai-fundamentals/asr-automation-speech-recognition/) **(Intermediate)** - Comprehensive 2025 guide to automatic speech recognition technology covering how ASR works, history of speech recognition, deep learning approaches, multilingual ASR (120+ languages), real-world applications, and latest models. Explains end-to-end ASR pipelines, acoustic models, language models, and inference optimization. Perfect for understanding modern ASR systems. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully free, detailed technical guide
  - ğŸ“œ Coverage: ASR fundamentals, history, deep learning, multilingual
  - ğŸ“ Topics: 120+ language support, real-world applications, latest models
  - ğŸ’ª Scope: Comprehensive ASR overview 2025
  - [Tags: intermediate asr guide deep-learning multilingual fundamentals 2025]

- [Complete Guide to Text-to-Speech (TTS) Technology 2025](https://picovoice.ai/blog/complete-guide-to-text-to-speech/) **(Intermediate)** - Comprehensive 2025 guide to text-to-speech technology covering on-device TTS, cloud TTS, streaming TTS, neural TTS architectures, quality metrics, and benchmarking approaches. Explains TTS technology evolution, voice characteristics, prosody control, multilingual synthesis, and selection criteria for choosing TTS solutions. Updated with latest 2025 models and trends. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully free, comprehensive technical guide
  - ğŸ“œ Coverage: On-device, cloud, streaming TTS architectures
  - ğŸ’¡ Topics: Voice characteristics, prosody, neural TTS, benchmarking
  - ğŸ“ Scope: Selection criteria, latest 2025 models, quality metrics
  - [Tags: intermediate tts guide neural-tts benchmarking prosody-control 2025]

- [The Best Speech Recognition API in 2025: A Head-to-Head Comparison](https://voicewriter.io/blog/best-speech-recognition-api-2025) **(Intermediate)** - Comparative analysis and benchmark of major speech recognition APIs in 2025 including AWS Transcribe, Google Cloud Speech-to-Text, and Microsoft Azure Speech Services. Covers API features, accuracy benchmarks, pricing models, supported languages, and real-world performance metrics to help you choose the right speech API. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully free, detailed API comparison
  - ğŸ’ª Providers: AWS, Google Cloud, Microsoft Azure
  - ğŸ““ Metrics: Accuracy, latency, language support, pricing
  - ğŸ¯ Purpose: API selection, benchmark comparison
  - [Tags: intermediate api-comparison aws-transcribe google-cloud azure-speech 2025]

---

## ğŸ› ï¸ Tools & Software

### ğŸŸ¢ Beginner-Friendly

- [Speech Data Builder](https://fs-17.github.io/SpeechDataBuilder/) â€“ Free web-based tool for creating high-quality speech datasets for TTS and STT models. Features automatic AI transcription (Google/OpenAI), waveform editor, interactive regions, and exports in LJSpeech, CSV, JSON formats. Perfect for building custom voice datasets without coding. (ğŸŸ¢ Beginner)
  - ğŸ“– Access: Fully free, browser-based
  - ğŸ› ï¸ Hands-on: No installation required
  - ğŸ“œ Features: AI transcription, dataset export
  - ğŸ’¾ Formats: LJSpeech, CSV, JSON, TXT
  - [Tags: dataset-creation tool browser-based tts stt no-code 2025]

- [ChatTTS: Open Source Text-to-Speech](https://github.com/2noise/ChatTTS) â€“ Open-source generative TTS model optimized for natural, conversational speech synthesis. Delivers high-quality voice output with emotional control and multiple speaker options. Features YouTube tutorial demonstrating installation, basic usage, and integration with Ollama for local deployment. Perfect for beginners building voice applications. (ğŸŸ¢ Beginner to ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully open, MIT license
  - ğŸ›ï¸ Authority: Community-driven (30,000+ GitHub stars)
  - ğŸ› ï¸ Hands-on: Python package with simple API
  - ğŸ“œ Features: Natural speech, emotion control, speaker variety
  - ğŸ“º Tutorial: YouTube installation guide available
  - â­ GitHub: 30,000+ stars, actively maintained
  - [Tags: chattts open-source tts conversational-speech python beginner-friendly 2025]

### ğŸŸ¡ Intermediate

- [OpenAI Whisper](https://github.com/openai/whisper) â€“ State-of-the-art open-source automatic speech recognition (ASR) model trained on 680,000 hours of multilingual data. Achieves human-level accuracy on English transcription and supports 99 languages with robust performance on accents, background noise, and technical language. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully open, MIT license
  - ğŸ›ï¸ Authority: OpenAI (official release)
  - ğŸ› ï¸ Hands-on: Python package, command-line tool
  - ğŸ“œ Features: 99 languages, robust ASR
  - â­ GitHub: 70,000+ stars
  - [Tags: whisper openai asr speech-recognition multilingual state-of-the-art 2025]

- [Parler TTS: Open Source Text-to-Speech](https://github.com/huggingface/parler-tts) â€“ High-quality open-source TTS model from Hugging Face trained on 45,000+ hours of audio data. Features fine-grained control over speaker characteristics including gender, pitch, speaking rate, and emotion. Available in two variants: Large (2.4B parameters) and Mini (880M parameters). Ideal for projects requiring customizable, natural-sounding voice synthesis. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully open, Apache 2.0 license
  - ğŸ›ï¸ Authority: Hugging Face (official release)
  - ğŸ› ï¸ Hands-on: Python package with Transformers library
  - ğŸ“œ Features: Voice control (gender/pitch/rate), 45K hours training, 2 model sizes
  - â­ GitHub: 2,000+ stars, actively maintained
  - ğŸ’¾ Models: Large (2.4B) and Mini (880M parameters)
  - [Tags: parler-tts huggingface voice-control tts open-source transformers 2025]

- [AssemblyAI Speech-to-Text API Guide (2025)](https://assemblyai.com/blog/the-top-free-speech-to-text-apis-and-open-source-engines) â€“ Comprehensive guide comparing top free speech-to-text APIs and open-source engines including AssemblyAI, Google Cloud Speech-to-Text, and AWS Transcribe. Covers API features, pricing, accuracy, multilingual support, speaker diarization, and real-world use cases. Updated 2025 with latest models and free tier options. (ğŸŸ¡ Intermediate)
  - ğŸ“– Access: Fully free, detailed comparison guide
  - ğŸ›ï¸ Authority: AssemblyAI (industry leader)
  - ğŸ“œ Covers: 3+ major STT providers, free tier comparisons
  - ğŸ’¡ Features: Diarization, sentiment analysis, punctuation
  - ğŸ“Š Comparison: API pricing, accuracy metrics, language support
  - [Tags: stt-apis comparison free-tier assemblyai google-cloud aws-transcribe 2025]

### ğŸ”´ Advanced

- [ESPnet (End-to-End Speech Processing Toolkit)](https://github.com/espnet/espnet) â€“ Comprehensive open-source toolkit for end-to-end speech processing including ASR, TTS, speech translation, speech enhancement, and more. Built on PyTorch with extensive pre-trained models, recipes for 100+ corpora, and production-ready pipelines. (ğŸ”´ Advanced)
  - ğŸ“– Access: Fully open, Apache 2.0 license
  - ğŸ›ï¸ Authority: Research community toolkit
  - ğŸ› ï¸ Hands-on: PyTorch-based framework
  - ğŸ“œ Features: ASR, TTS, translation, 100+ recipes
  - â­ GitHub: 8,000+ stars
  - [Tags: espnet end-to-end pytorch asr tts speech-translation research 2025]

- [SpeechBrain: A General-Purpose Speech Toolkit](https://github.com/speechbrain/speechbrain) â€“ Comprehensive all-in-one PyTorch-based speech toolkit supporting ASR, speaker recognition, speech enhancement, speech separation, text-to-speech, and voice conversion. Features 100+ ready-to-use recipes, pre-trained models for major tasks, and modular architecture for research and production. Built for both beginners and researchers with extensive documentation and tutorials. (ğŸ”´ Advanced)
  - ğŸ“– Access: Fully open, Apache 2.0 license
  - ğŸ›ï¸ Authority: SpeechBrain Team (research-grade quality)
  - ğŸ› ï¸ Hands-on: PyTorch framework with 100+ recipes
  - ğŸ“œ Features: ASR, speaker-ID, enhancement, separation, TTS, voice-conversion
  - â­ GitHub: 8,000+ stars, actively maintained
  - ğŸ¯ Use cases: End-to-end speech pipelines, custom model training
  - [Tags: speechbrain pytorch asr speaker-verification speech-enhancement tts advanced-toolkit 2025]

---

## ğŸ“„ Research & Advanced Topics

### ğŸ”´ Advanced

- [Wav2Vec 2.0 (Facebook AI)](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/) â€“ Self-supervised learning framework for speech representation from raw audio. Pre-trains on unlabeled audio then fine-tunes with minimal labeled data, achieving state-of-the-art results with 100x less labeled data than traditional approaches. Revolutionary approach to low-resource ASR. (ğŸ”´ Advanced)
  - ğŸ“– Access: Research blog + model open-source
  - ğŸ›ï¸ Authority: Meta AI Research
  - ğŸ“œ Impact: Breakthrough in self-supervised speech
  - ğŸ› ï¸ Implementation: Available in Fairseq
  - [Tags: wav2vec self-supervised meta-ai low-resource breakthrough 2020]

---

## ğŸ”— Related Resources

**See also:**
- [Natural Language Processing](./natural-language-processing.md) - Text processing and language understanding
- [Deep Learning & Neural Networks](./deep-learning-neural-networks.md) - Neural architectures for speech
- [AI Tools & Frameworks](./ai-tools-frameworks.md) - PyTorch, TensorFlow for audio
- [Datasets & Benchmarks](./datasets-benchmarks.md) - Additional audio datasets

**Cross-reference:**
- [Generative AI](./generative-ai.md) - Voice cloning and synthesis
- [Machine Learning Fundamentals](./machine-learning-fundamentals.md) - ML basics for audio

**Prerequisites:**
- [Mathematics for AI](./mathematics-for-ai.md) - Signal processing fundamentals
- [Machine Learning Fundamentals](./machine-learning-fundamentals.md) - Basic ML concepts

---

## ğŸ¤ Contributing

Found a great free audio & speech processing resource? We'd love to add it!

**To contribute, use this format:**
```
- [Resource Name](URL) â€“ Clear description highlighting value and unique features. (Difficulty Level)
  - ğŸ“– Access: [access details]
  - ğŸ›ï¸ Authority: [source/organization]
  - [Tags: keyword1 keyword2 keyword3]
```

**Ensure all resources are:**
- âœ… Completely free to access (no payment required)
- âœ… Openly available (no authentication barriers for core content)
- âœ… High-quality and educational
- âœ… Relevant to audio and speech processing
- âœ… From reputable sources (universities, official docs, established platforms)

---

**Last Updated:** January 6, 2026 | **Total Resources:** 30 (Courses: 7 + Datasets: 5 + Tools: 10 + Research: 1 + Guides: 7)

**Keywords:** audio-processing, speech-recognition, asr, automatic-speech-recognition, text-to-speech, tts, speech-synthesis, voice-processing, speech-datasets, common-voice, librispeech, openslr, whisper, espnet, wav2vec, multilingual-speech, ted-lium, voxforge, speechocean, digital-speech-processing, voice-cloning, speech-to-speech, chattts, parler-tts, speechbrain, stanford-cs224s, speech-synthesis-agents-2025, emotional-tts, audio-foundation-models, spoken-language-models, ttic-2025