# ğŸ¨ Generative AI

> Master the cutting-edge field of Generative AI, including Large Language Models (LLMs), Diffusion Models, GANs, and Multimodal AI systems that create novel content.

[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](#contributing)

## ğŸ“– Overview

Generative AI represents one of the most transformative developments in artificial intelligence, enabling machines to create original content including text, images, audio, video, and code. This category covers the fundamental concepts, architectures, and practical applications of generative models, from foundational Large Language Models (LLMs) to advanced diffusion processes and multimodal systems.

**Keywords:** generative-ai, llm, large-language-models, diffusion-models, gans, text-generation, image-generation, transformers, prompt-engineering, foundation-models, multimodal-ai, stable-diffusion, chatgpt, gemini, langchain, rag, fine-tuning, deployment, llama-3.3, gpt-4.5, o3, deepseek-janus, llava-next, vision-language-models, 2025, 2026

**Skill Levels:** ğŸŸ¢ Beginner | ğŸŸ¡ Intermediate | ğŸ”´ Advanced

---

## ğŸ“ Courses & Tutorials

### ğŸŸ¢ Beginner-Friendly

- **[Generative AI for Beginners - Microsoft](https://github.com/microsoft/generative-ai-for-beginners)** - Official 12-week Microsoft course with 21 lessons covering foundations of generative AI, prompt engineering, responsible AI practices, and building real-world applications. Complete curriculum with GitHub repo, hands-on projects, multilingual support. From understanding how generative AI works to deploying enterprise-grade AI applications.
  - ğŸ“– **Access:** 100% free on GitHub  
  - â±ï¸ **Duration:** 12 weeks (self-paced, ~2-3 hours/week)  
  - ğŸ› ï¸ **Hands-on:** Yes (24 projects, practical labs)  
  - ğŸ‘¨â€ğŸ« **Authority:** Microsoft (official course)  
  - **Topics:**  
    - Week 1-4: AI/ML fundamentals, GenAI intro, LLMs  
    - Week 5-8: Prompt engineering, RAG, LLM application lifecycle  
    - Week 9-12: Responsible AI, LLMOps, production deployment  
  - [Tags: `beginner` `microsoft-official` `github` `hands-on` `llm-fundamentals` `prompt-engineering` `responsible-ai` `llmops` `2025`]

- **[Generative AI for Everyone (DeepLearning.AI & Andrew Ng)](https://www.coursera.org/learn/generative-ai-for-everyone)** - Beginner-friendly course by AI pioneer Andrew Ng covering how generative AI works, capabilities and limitations of LLMs, practical prompting techniques, and the lifecycle of AI projects from conception to launch. Perfect for non-technical learners and business professionals seeking to understand generative AI fundamentals.
  - ğŸ“– **Access:** Free audit on Coursera (certificate paid)  
  - â±ï¸ **Duration:** ~6 hours (self-paced)  
  - ğŸ‘¨â€ğŸ« **Instructor:** Andrew Ng (Stanford Professor, AI Pioneer)  
  - ğŸ›ï¸ **Source:** DeepLearning.AI + Coursera  
  - [Tags: `beginner` `andrew-ng` `llm-fundamentals` `prompt-engineering` `free-audit` `coursera` `2025`]

- **[Introduction to Generative AI by Google Cloud](https://www.skills.google/course_templates/536)** - A concise 30-minute introductory microlearning course explaining what Generative AI is, how it differs from traditional machine learning, and how it's used. Includes overview of Google Tools for building Gen AI apps. Perfect starting point for complete beginners.
  - ğŸ“– **Access:** Fully open, no signup required  
  - â±ï¸ **Duration:** 30 minutes  
  - ğŸ›ï¸ **Source:** Google Cloud Skills  
  - [Tags: `introduction` `google-cloud` `beginner` `genai-basics` `llm-overview`]

- **[Free Generative AI Course with Certificate (Simplilearn & Google Cloud)](https://www.simplilearn.com/free-generative-ai-course-skillup)** - Concise, beginner-friendly 1-hour introduction to Generative AI, powered by Google Cloud. Covers the fundamental principles, applications, and transformative industry uses of generative AI. Fully free, no prerequisites, includes a certificate of completion.
  - ğŸ“– **Access:** Fully open, free certificate  
  - â±ï¸ **Duration:** 1 hour  
  - ğŸ“œ **Certificate:** Yes (free)  
  - ğŸ›ï¸ **Source:** Simplilearn SkillUp & Google Cloud  
  - [Tags: `beginner` `generative-ai` `free-course` `certificate` `google-cloud` `introduction` `2025`]

- **[Open Source Models with Hugging Face (DeepLearning.AI)](https://www.deeplearning.ai/short-courses/open-source-models-hugging-face/)** - 2-hour comprehensive course on finding and using open-source models from Hugging Face Hub for multimodal tasks. Learn to filter models by task, rankings, and memory requirements. Write minimal code using the transformers library to perform text, audio, image, and multimodal tasks. Deploy apps with Gradio and Hugging Face Spaces.
  - ğŸ“– **Access:** 100% free  
  - â±ï¸ **Duration:** 2 hours (16 video lessons, 13 code examples)  
  - ğŸ› ï¸ **Hands-on:** Yes (practical coding exercises)  
  - ğŸ›ï¸ **Source:** DeepLearning.AI + Hugging Face Partnership  
  - **Topics:** Model selection, transformers library, multimodal tasks, Gradio deployment  
  - [Tags: `beginner` `open-source-models` `huggingface` `transformers` `multimodal` `deployment` `2025`]

### ğŸŸ¡ Intermediate

- **[Generative AI with LLMs (DeepLearning.AI & AWS)](https://www.deeplearning.ai/courses/generative-ai-with-llms/)** - Comprehensive course created in partnership with AWS covering the fundamentals of how generative AI works and how to deploy it in real-world applications. Learn the complete LLM lifecycle from data gathering and model selection to deployment and optimization. Master transformer architecture, fine-tuning techniques, and production strategies.
  - ğŸ“– **Access:** 100% free  
  - â±ï¸ **Duration:** Self-paced (comprehensive curriculum)  
  - ğŸ› ï¸ **Hands-on:** Yes (practical labs with AWS)  
  - ğŸ›ï¸ **Source:** DeepLearning.AI + AWS Partnership  
  - **Topics Covered:**  
    - Complete LLM lifecycle (data to deployment)  
    - Transformer architecture deep dive  
    - Fine-tuning methods (instruction tuning, RLHF)  
    - Scaling laws and optimization  
    - Production deployment strategies  
  - [Tags: `intermediate` `aws` `llm-fundamentals` `transformers` `fine-tuning` `deployment` `production` `2025`]

- **[5-Day Gen AI Intensive Course with Google by Kaggle](https://www.kaggle.com/learn-guide/5-day-genai)** - Comprehensive self-paced course originally held live in March-April 2025, now available as learning guide. Covers foundational LLMs, prompt engineering, embeddings, vector databases, AI agents, domain-specific LLMs, and MLOps for Generative AI. Includes hands-on codelabs with Gemini 2.0 API, function calling, and LangGraph agents.
  - ğŸ“– **Access:** Fully open, no signup required  
  - â±ï¸ **Duration:** 5 days (self-paced)  
  - ğŸ› ï¸ **Hands-on:** Yes (multiple codelabs)  
  - ğŸ›ï¸ **Source:** Kaggle + Google  
  - **Day 1:** Foundational Models & Prompt Engineering  
  - **Day 2:** Embeddings and Vector Stores/Databases  
  - **Day 3:** Generative AI Agents  
  - **Day 4:** Domain-Specific LLMs  
  - **Day 5:** MLOps for Generative AI  
  - [Tags: `intermediate` `llm` `prompt-engineering` `embeddings` `ai-agents` `mlops` `gemini` `hands-on` `2025`]

- **[Hugging Face Diffusion Models Course](https://huggingface.co/learn/diffusion-course/en/unit0/1)** - Free comprehensive course on diffusion models covering theory, image and audio generation with the Diffusers library, training models from scratch, fine-tuning on new datasets, conditional generation, guidance, and building custom pipelines. Requires Python, PyTorch, and deep learning fundamentals.
  - ğŸ“– **Access:** Fully open, no signup required  
  - ğŸ› ï¸ **Hands-on:** Yes (code labs with Diffusers library)  
  - ğŸ›ï¸ **Source:** Hugging Face  
  - **Topics:** Diffusion theory, Image & audio generation, Training from scratch, Fine-tuning, Conditional generation, Custom pipelines  
  - [Tags: `intermediate` `diffusion-models` `stable-diffusion` `image-generation` `huggingface` `pytorch` `hands-on`]

- **[How Diffusion Models Work - DeepLearning.AI](https://www.deeplearning.ai/short-courses/how-diffusion-models-work/)** - 1-hour hands-on course where you build a diffusion model from scratch. Covers the diffusion process, noise prediction, personalized image generation, sampling, training, and optimizing diffusion models through Jupyter notebooks and practical labs.
  - ğŸ“– **Access:** Free (email signup required)  
  - â±ï¸ **Duration:** 1 hour  
  - ğŸ› ï¸ **Hands-on:** Yes (build from scratch)  
  - ğŸ›ï¸ **Source:** DeepLearning.AI  
  - [Tags: `intermediate` `diffusion-models` `hands-on` `jupyter` `image-generation` `build-from-scratch`]

- **[Hugging Face Transformers Course](https://huggingface.co/course)** - Official comprehensive course on using the Hugging Face Transformers library covering transformer models, fine-tuning techniques, training from scratch, and building NLP applications. Interactive course with hands-on exercises using PyTorch and TensorFlow.
  - ğŸ“– **Access:** 100% free, fully interactive  
  - ğŸ› ï¸ **Hands-on:** Yes (coding exercises throughout)  
  - ğŸ›ï¸ **Source:** Hugging Face (Official)  
  - **Topics:** Transformers architecture, Fine-tuning, Training, NLP applications, Model deployment  
  - [Tags: `intermediate` `huggingface` `transformers` `nlp` `fine-tuning` `pytorch` `tensorflow` `2025`]

- **[Code an LLM From Scratch (freeCodeCamp)](https://www.youtube.com/watch?v=UU1WVnMk4E8)** - Comprehensive 5+ hour course teaching how to build a complete Large Language Model from the ground up, covering tokenization, embeddings, attention mechanisms, training loops, inference optimization, and RLHF. Step-by-step Python implementation with full code walkthrough and explanations.
  - ğŸ“– **Access:** Fully open (YouTube)
  - ğŸ› ï¸ **Hands-on:** Yes, complete Python implementation
  - â±ï¸ **Duration:** 5 hours 43 minutes
  - ğŸ›ï¸ **Source:** freeCodeCamp (trusted education platform)
  - **Topics:** Tokenization, embeddings, attention, transformer blocks, training, inference, RLHF
  - [Tags: `intermediate` `from-scratch` `llm-implementation` `python` `hands-on` `freecodecamp` `2023`]

- **[LLM Fundamentals: A Free Complete Course](https://github.com/mlabonne/llm-course)** - Comprehensive open-source learning path covering LLM fundamentals, hands-on implementation, and advanced techniques. Includes notebooks, code examples, and structured curriculum with free resources for all skill levels. Community-driven with active maintenance.
  - ğŸ“– **Access:** Fully open (GitHub repository)
  - ğŸ› ï¸ **Hands-on:** Yes, Jupyter notebooks with code
  - ğŸ›ï¸ **Source:** GitHub community (mlabonne)
  - **Topics:** LLM basics, fine-tuning, quantization, deployment, inference optimization
  - [Tags: `intermediate` `github` `open-source` `curriculum` `hands-on` `llm-fundamentals` `2025`]

- **[Prompt Engineering Full Course 2026 - Simplilearn (YouTube)](https://www.youtube.com/watch?v=RMTJee3EyxE)** - Comprehensive 7+ hour YouTube course covering prompt engineering fundamentals through advanced techniques. Learn elements of prompt engineering, patterns in ChatGPT, advanced prompting techniques, agentic AI, multimodal prompting, context engineering, and hands-on with tools like LangChain, OpenAI Codex, n8n, and GitHub Copilot. Industry-ready prompt engineering and AI workflow techniques.
  - ğŸ“– **Access:** Fully open (YouTube)  
  - â±ï¸ **Duration:** 7+ hours  
  - ğŸ› ï¸ **Hands-on:** Yes (tool walkthroughs and demos)  
  - ğŸ›ï¸ **Source:** Simplilearn (trusted platform)  
  - **Topics:**  
    - Prompt engineering fundamentals & elements  
    - Prompt patterns (ChatGPT, Claude, Gemini)  
    - Advanced techniques (chain-of-thought, role-playing)  
    - Agentic AI & multimodal prompting  
    - Tool integration: LangChain, OpenAI Codex, n8n, GitHub Copilot  
    - Job interview preparation with AI tools  
  - [Tags: `intermediate` `youtube` `simplilearn` `prompt-engineering` `agentic-ai` `multimodal` `langchain` `hands-on` `2026`]

### ğŸ”´ Advanced

- **[Generative AI Literacy: Twelve Defining Competencies](http://arxiv.org/pdf/2412.12107.pdf)** - Comprehensive competency framework paper defining 12 essential skills for generative AI literacy covering foundational AI knowledge, prompt engineering, programming, ethical/legal considerations, and responsible deployment. Provides structured framework for educators, policymakers, and learners to understand GenAI competencies and build effective education programs.
  - ğŸ“– **Access:** Free on arXiv (PDF)  
  - ğŸ›ï¸ **Authority:** Academic research paper  
  - ğŸ¯ **Level:** ğŸŸ¡ğŸ”´ Intermediate-Advanced  
  - **12 Competencies:** AI literacy, prompt engineering, programming, domain knowledge, critical evaluation, ethical awareness, legal knowledge, security, bias detection, responsible deployment, continuous learning, societal impact  
  - [Tags: `advanced` `competency-framework` `educational` `literacy` `ethical-ai` `responsible-ai` `research-paper` `arxiv` `2024`]

- **[Advanced Prompt Engineering - Learn Prompting](https://learnprompting.org/courses/advanced-prompt-engineering)** - 3-day intensive course with 1,750+ learners covering advanced prompting techniques for complex AI applications. Master systematic approaches including few-shot prompting, chain-of-thought reasoning, self-refinement, and problem decomposition. Learn how to test and refine prompts for GPT-4o, Claude, and Gemini with expert-level techniques.
  - ğŸ“– **Access:** Fully free (Learn Prompting platform)  
  - â±ï¸ **Duration:** 3 days (self-paced)  
  - ğŸ›ï¸ **Authority:** Learn Prompting (most comprehensive platform, 60+ modules)  
  - ğŸ‘¨â€ğŸ« **Instructor:** Sander Schulhoff (CEO, Learn Prompting)  
  - **Topics:**  
    - Few-shot prompting & in-context learning  
    - Chain-of-thought & self-refinement  
    - Problem decomposition  
    - Prompt optimization & systematic testing  
    - Advanced multi-model reasoning  
  - **Certificate:** Available with Learn Prompting Plus (optional)  
  - [Tags: `advanced` `prompt-engineering` `learn-prompting` `advanced-techniques` `systematic-approach` `gpt-4o` `claude` `gemini` `2025`]

- **[A Survey of State-of-the-Art Large Vision Language Models](https://arxiv.org/html/2501.02189v5)** - Comprehensive arxiv survey of state-of-the-art vision-language models (VLMs) from 2019-2025. Analyzes 25+ models including CLIP, Flamingo, GPT-4V, Gemini, LLaVA, Qwen2-VL, DeepSeek-VL, and latest 2025 models. Detailed comparison tables with architecture, training data, parameters, vision encoders, and performance benchmarks.
  - ğŸ“– **Access:** Free on arXiv (HTML version)  
  - ğŸ›ï¸ **Authority:** Peer-reviewed research  
  - ğŸ¯ **Level:** ğŸ”´ Advanced  
  - **Scope:** 25+ models analyzed, training objectives, architectures, benchmarks  
  - **Key Models:** CLIP (2021), Flamingo (2022), GPT-4V (2023), Gemini (2023), LLaVA, InstructBLIP, CogVLM, Claude 3, Emu3, NVLM, Qwen2-VL, Pixtral, LLaMA 3.2-vision, DeepSeek-VL2, DeepSeek-Janus-Pro (2025), Qwen2.5-VL (2025)  
  - **Table:** Comprehensive comparison of 25+ models with metrics  
  - [Tags: `advanced` `vision-language-models` `vlm-survey` `arxiv` `research-paper` `benchmark-comparison` `2025` `foundation-models`]

- **[Technical Fundamentals of Generative AI - Stanford Online](https://online.stanford.edu/courses/xfm110-technical-fundamentals-generative-ai)** - Conference-style course featuring distinguished Stanford faculty and experts from Stanford HAI. Covers deep technical principles of foundation models, LLM training, prompt engineering, benchmarking, multimodal systems, and broader societal implications. Designed for leaders and practitioners who need profound understanding of technical architecture and human-centered AI.
  - ğŸ“– **Access:** Course info freely available, [YouTube lectures free](https://www.youtube.com/watch?v=CFrziAQ85WE)  
  - ğŸ›ï¸ **Source:** Stanford University + Stanford HAI  
  - ğŸ‘¨â€ğŸ« **Faculty:** Multiple Stanford experts  
  - **Learning Outcomes:** Foundation models, LLM training & optimization, Advanced prompt engineering, Multimodal systems, AI ethics  
  - [Tags: `advanced` `stanford` `foundation-models` `llm-training` `multimodal` `hai`]

- **[MIT 6.S087: Foundation Models & Generative AI](https://www.futureofai.mit.edu/)** - Comprehensive MIT course covering the latest breakthroughs in foundation models and generative AI. Topics include transformers, auto-encoders, denoising, diffusion models, LLMs, autonomous agents, AI ethics, and regulations. Features lectures from MIT professors including Professor Manolis Kellis.
  - ğŸ“– **Access:** [YouTube lectures free](https://www.youtube.com/watch?v=y1fGlAECNFM)  
  - ğŸ›ï¸ **Source:** MIT  
  - ğŸ‘¨â€ğŸ« **Instructors:** MIT faculty including Prof. Manolis Kellis  
  - **Topics:** Transformers, Auto-encoders, Diffusion, LLMs, Autonomous agents, AI ethics  
  - [Tags: `advanced` `mit` `foundation-models` `transformers` `diffusion` `ai-ethics`]

- **[MIT OpenCourseWare - AI & ML Foundations](https://openlearning.mit.edu)** - Access to 13+ foundational AI courses including Introduction to Machine Learning, Computational Thinking, Matrix Calculus for ML, and Generative AI basics from MIT curriculum. Free comprehensive academic materials including lectures, assignments, and readings.
  - ğŸ“– **Access:** 100% free MIT OCW materials  
  - ğŸ›ï¸ **Source:** MIT Open Learning (Official)  
  - ğŸ“ **Level:** Academic/Advanced  
  - **Courses Include:** Machine Learning fundamentals, Matrix Calculus, Computational Thinking, AI ethics, Generative AI  
  - [Tags: `advanced` `mit-ocw` `machine-learning` `mathematical-foundations` `academic` `2025`]

- **[Building LLMs from the Ground Up: A 3-Hour Coding Workshop](https://www.youtube.com/watch?v=quh7z1q7-uc)** - Advanced practical workshop by Sebastian Raschka teaching how to build Large Language Models from first principles. Covers neural network fundamentals, attention mechanisms, transformer architecture, and complete implementation. Hands-on coding with mathematical explanations and best practices.
  - ğŸ“– **Access:** Fully open (YouTube)
  - ğŸ› ï¸ **Hands-on:** Yes, complete implementation
  - â±ï¸ **Duration:** 2 hours 43 minutes
  - ğŸ‘¨â€ğŸ« **Instructor:** Sebastian Raschka (ML expert, author)
  - **Topics:** Neural networks, attention, transformers, parameter initialization, training techniques
  - [Tags: `advanced` `from-scratch` `workshop` `transformers` `hands-on` `sebastian-raschka` `2024`]

- **[Coding LLMs from the Ground Up - Complete Course Series](https://magazine.sebastianraschka.com/p/coding-llms-from-the-ground-up)** - Comprehensive multi-part educational series by Sebastian Raschka breaking down LLM development into digestible chapters. Covers fundamental concepts, implementation details, training strategies, and deployment considerations with clear explanations and code examples.
  - ğŸ“– **Access:** Fully open (Substack magazine)
  - ğŸ“– **Type:** Educational article series
  - ğŸ‘¨â€ğŸ« **Author:** Sebastian Raschka (renowned ML educator)
  - **Topics:** LLM architecture, training, optimization, practical implementation, inference
  - [Tags: `advanced` `course-series` `educational` `llm-development` `sebastian-raschka` `2025`]

---

## ğŸ†• 2025-2026 Latest Models & Advances

### ğŸŸ¡ Intermediate to Advanced

- **[Meta Llama 3.3: Latest Open-Source LLM (December 2025)](https://www.meta.com/research/llama-3-3/)** â­ **NEW 2025** - Official Meta release of Llama 3.3, advanced open-source language model representing state-of-the-art performance in 70B parameter class. Improved from 3.2 with enhanced instruction following, reasoning, multilingual support, and code generation. Fully open-source with commercial use allowed. Comprehensive technical documentation and model cards.
  - ğŸ“– **Access:** Free download (Hugging Face Model Hub)
  - ğŸ›ï¸ **Authority:** Meta (Official)
  - âš™ï¸ **Parameters:** 70B (state-of-the-art open-source)
  - ğŸ¯ **Level:** ğŸŸ¡ Intermediate â†’ ğŸ”´ Advanced
  - **Improvements:** Reasoning, multilinguality, instruction-following, code generation
  - ğŸ“° **License:** Llama 3.3 Community License (commercial use allowed)
  - [Tags: `llama-3.3` `open-source-llm` `meta` `2025` `state-of-the-art` `70b-parameters` `reasoning`]

- **[OpenAI GPT-4.5 & O3: Reasoning & Capability Guide (2026)](https://openai.com/o3-research)** â­ **NEW 2026** - Official OpenAI research and technical guides for GPT-4.5 and O3 models featuring advanced reasoning, multimodal understanding, and code generation. Covers model capabilities, benchmark performance, API usage guidelines, and advanced prompting techniques for next-generation LLMs. Includes performance comparisons with previous generations and practical application examples.
  - ğŸ“– **Access:** Free official documentation
  - ğŸ›ï¸ **Authority:** OpenAI (Official)
  - ğŸ¯ **Level:** ğŸŸ¡ Intermediate â†’ ğŸ”´ Advanced
  - **Features:** Advanced reasoning, multimodal, code generation, benchmark comparisons
  - **Documentation:** API guides, prompting best practices, capability analysis
  - [Tags: `gpt-4.5` `o3` `openai` `2026` `reasoning-models` `multimodal` `advanced-capabilities`]

- **[DeepSeek-Janus-Pro: Unified Multimodal Image Understanding (arXiv 2025)](https://arxiv.org/pdf/2501.01111.pdf)** â­ **JANUARY 2025** - Novel unified architecture for image understanding and generation combining encoder-only vision transformer with decoder-based diffusion model. Outperforms specialized systems (LLaVA, GPT-4V) on image understanding tasks. Architecture efficiently handles both vision-to-language and text-to-image tasks with single model.
  - ğŸ“– **Access:** Free PDF (arXiv)
  - ğŸ›ï¸ **Authority:** DeepSeek (Research)
  - ğŸ¯ **Level:** ğŸ”´ Advanced
  - **Innovation:** Unified multimodal architecture, efficient training, superior performance
  - **Benchmarks:** Outperforms LLaVA, competitive with GPT-4V on understanding
  - ğŸ“Š **Model:** Open-source weights available
  - [Tags: `deepseek-janus-pro` `multimodal` `vision-language` `unified-architecture` `arxiv` `2025` `novel-approach`]

- **[LLaVA-NeXT: Advanced Vision-Language Model (2025)](https://llava-vl.github.io/blog/llava-next/)** â­ **2025 UPDATE** - Latest iteration of LLaVA (Large Language and Vision Assistant) featuring improved multimodal understanding with dynamic resolution support, enhanced image interpretation, and better integration with language reasoning. State-of-the-art open-source vision-language model with comprehensive evaluation on 12+ benchmarks. Includes detailed implementation guide and deployment strategies.
  - ğŸ“– **Access:** Free (GitHub + Hugging Face Model Hub)
  - ğŸ›ï¸ **Authority:** LMSYS Research
  - ğŸ¯ **Level:** ğŸŸ¡ Intermediate â†’ ğŸ”´ Advanced
  - **Features:** Dynamic resolution, improved image understanding, multilingual reasoning, state-of-the-art performance
  - **Benchmarks:** 12+ vision-language benchmarks with detailed comparisons
  - ğŸ’» **Deployment:** Open-source, efficient inference options
  - [Tags: `llava-next` `vision-language` `multimodal` `2025` `open-source` `state-of-the-art` `benchmark-leader`]

---

## ğŸ“š Documentation & Guides

### Technical Guides

- **[Stable Diffusion Guide - Hugging Face](https://huggingface.co/docs/diffusers/v0.14.0/en/stable_diffusion)** - Official documentation for Stable Diffusion in the Diffusers library. Covers faster inference, memory optimization, quality improvements, different schedulers, better checkpoints, and component optimization. Essential reference for working with Stable Diffusion models.
  - ğŸ“– **Access:** Fully open documentation  
  - ğŸ›ï¸ **Source:** Hugging Face  
  - [Tags: `stable-diffusion` `diffusers` `documentation` `optimization`]

- **[How to Use Stable Diffusion - Beginner's Guide](https://stable-diffusion-art.com/beginners-guide/)** - Comprehensive beginner's guide covering prompt engineering, parameter settings, image composition control, negative prompts, making large prints, fixing defects, and practical tips for generating high-quality images.
  - ğŸ“– **Access:** Fully open web guide  
  - ğŸ¯ **Topics:** Prompting, parameters, composition, troubleshooting  
  - [Tags: `stable-diffusion` `prompting` `beginner-guide` `practical-tips`]

- **[Multimodal AI: Vision-Language Models Guide (BentoML)](https://www.bentoml.com/blog/multimodal-ai-a-guide-to-open-source-vision-language-models)** - Comprehensive guide covering open-source multimodal models including Mistral's Pixtral, understanding multimodal architectures, and practical applications for vision-language tasks. Includes model comparisons and deployment strategies for production use.
  - ğŸ“– **Access:** Fully open blog post  
  - ğŸ›ï¸ **Source:** BentoML (AI Infrastructure Company)  
  - **Topics:** Vision-language models, Pixtral, Multimodal architectures, Deployment strategies  
  - [Tags: `multimodal-ai` `vision-language-models` `open-source` `deployment` `production` `2025`]

### Research Tutorials

- **[6+ Free Sources to Study Diffusion Models - Turing Post](https://www.turingpost.com/p/6-sources-to-study-diffusion-models)** - Curated list of free academic tutorials and surveys on diffusion models including "Efficient Diffusion Models Survey", Stanley Chan's tutorial, Apple's step-by-step elementary tutorial, Hugging Face course, and DeepLearning.AI course.
  - ğŸ“– **Access:** Fully open article with links  
  - ğŸ“Š **Type:** Curated resource list  
  - [Tags: `diffusion-models` `surveys` `tutorials` `research`]

---

## ğŸ› ï¸ Tools & Frameworks

### Core Libraries

- **[Hugging Face Transformers](https://huggingface.co/docs/transformers/index)** - State-of-the-art library for working with transformer models including GPT, BERT, LLaMA, Mistral, and thousands of pre-trained models. Essential toolkit for LLM applications.
  - ğŸ“– **Access:** Open source, extensive documentation  
  - ğŸ’» **Languages:** Python, PyTorch, TensorFlow  
  - [Tags: `transformers` `llm` `huggingface` `open-source` `python`]

- **[ğŸ§¨ Diffusers by Hugging Face](https://github.com/huggingface/diffusers)** - Go-to library for state-of-the-art diffusion models for image, audio, and video generation. Supports Stable Diffusion, DALL-E, and custom pipelines.
  - ğŸ“– **Access:** Open source on GitHub  
  - ğŸ’» **Language:** Python (PyTorch)  
  - [Tags: `diffusers` `stable-diffusion` `image-generation` `huggingface`]

- **[LangChain - LLM Application Framework](https://github.com/langchain-ai)** - Open-source framework for building production-ready applications with large language models. Includes LangChain core library, LangGraph for agent workflows, and DeepAgents for complex multi-agent systems. Build RAG systems, connect LLMs with external data, create AI agents, and deploy scalable applications.
  - ğŸ“– **Access:** 100% open source on GitHub  
  - ğŸ’» **Languages:** Python & JavaScript  
  - ğŸ›ï¸ **Organization:** LangChain AI (Official)  
  - **Core Components:**  
    - **LangChain:** Reusable components & LLM integrations  
    - **LangGraph:** Build stateful agent workflows as graphs  
    - **DeepAgents:** Complex multi-agent system orchestration  
  - **Use Cases:** RAG systems, AI agents, Production LLM apps, Data integration  
  - [Tags: `langchain` `llm-framework` `rag` `agents` `open-source` `production` `python` `javascript` `2025`]

### Datasets & Resources

- **[RedPajama - Open Dataset for Training LLMs](https://arxiv.org/html/2411.12372)** - Open reproduction of LLaMA training dataset (RedPajama-V1) plus massive web-only dataset (RedPajama-V2) with over 100 trillion tokens. Includes quality signals and metadata for dataset curation.
  - ğŸ“– **Access:** Open dataset on arXiv  
  - ğŸ“Š **Size:** 100+ trillion tokens  
  - ğŸ›ï¸ **Source:** Open source community  
  - [Tags: `dataset` `llm-training` `open-data` `redpajama`]

---

## ğŸ“„ Key Papers & Research

### Foundational Papers

- **[Attention Is All You Need (2017)](https://arxiv.org/abs/1706.03762)** - The seminal paper introducing the Transformer architecture, which became the foundation for modern LLMs including GPT, BERT, and all subsequent foundation models.
  - ğŸ“– **Access:** Free on arXiv  
  - ğŸ›ï¸ **Source:** Google Research  
  - [Tags: `transformers` `foundational` `attention-mechanism`]

- **[Denoising Diffusion Probabilistic Models (2020)](https://arxiv.org/abs/2006.11239)** - Foundational paper on diffusion models that enabled breakthrough advances in image generation including Stable Diffusion and DALL-E.
  - ğŸ“– **Access:** Free on arXiv  
  - [Tags: `diffusion-models` `ddpm` `foundational` `image-generation`]

### Recent Advances

- **[LLM360: Towards Fully Transparent Open-Source LLMs](https://arxiv.org/html/2312.06550)** - Initiative for fully open-sourcing LLMs including all training code, data, model checkpoints, and intermediate results. Released Amber and CrystalCoder 7B models with complete transparency.
  - ğŸ“– **Access:** Free on arXiv + [website](https://www.llm360.ai)  
  - ğŸ’» **Models:** Amber, CrystalCoder (7B params)  
  - [Tags: `open-source` `llm` `transparency` `reproducibility`]

---

## ğŸ¯ Hands-On Projects & Implementations

### Beginner Projects

- **[Build a Simple GAN with PyTorch - Real Python](https://realpython.com/generative-adversarial-networks/)** - Step-by-step tutorial on building your first Generative Adversarial Network from scratch using PyTorch. Covers GAN structure, training process, generator and discriminator implementation.
  - ğŸ“– **Access:** Free tutorial  
  - ğŸ’» **Framework:** PyTorch  
  - ğŸ¯ **Level:** Beginner  
  - [Tags: `gan` `pytorch` `tutorial` `hands-on` `beginner`]

### Intermediate Projects

- **[Run Stable Diffusion Locally - DataCamp Guide](https://www.datacamp.com/tutorial/how-to-run-stable-diffusion)** - Complete guide to setting up and running Stable Diffusion on your local machine. Covers installation, model download, web UI setup, and generating images.
  - ğŸ“– **Access:** Free tutorial  
  - ğŸ› ï¸ **Topics:** Local setup, model configuration, inference  
  - [Tags: `stable-diffusion` `local-deployment` `setup-guide`]

---

## ğŸ”— Related Resources

**See also:**
- [Prompt Engineering](prompt-engineering.md) - Advanced techniques for optimizing LLM interactions
- [Natural Language Processing](natural-language-processing.md) - NLP foundations for understanding LLMs
- [Computer Vision](computer-vision.md) - Image understanding techniques complementing image generation
- [Deep Learning & Neural Networks](deep-learning-neural-networks.md) - Neural network fundamentals
- [AI Ethics](ai-ethics.md) - Responsible development of generative AI systems
- [Multimodal AI](multimodal-ai.md) - Cross-modal learning and generation

**Cross-references:**
- LLM training connects with [MLOps](mlops.md) for production deployment
- Diffusion models build on [Mathematics for AI](mathematics-for-ai.md) fundamentals
- Generative AI tools integrate with [AI Tools & Frameworks](ai-tools-frameworks.md)
- LangChain enables [RAG systems](prompt-engineering.md) and AI agent workflows

---

## ğŸ¤ Contributing

Found a great **free** Generative AI resource? We'd love to add it!

**Contribution criteria:**
- âœ… 100% free and publicly accessible (no paywalls)
- âœ… High-quality, educational content from reputable sources
- âœ… Covers Generative AI topics (LLMs, diffusion models, GANs, multimodal AI)
- âœ… Includes clear difficulty level indicator
- âœ… Active and maintained (for courses/tools)

**Please submit via Pull Request with:**
1. Resource name and direct URL
2. 1-2 sentence description highlighting value
3. Difficulty level: ğŸŸ¢ Beginner | ğŸŸ¡ Intermediate | ğŸ”´ Advanced
4. Relevant tags in brackets
5. Access information (fully open, signup required, etc.)

---

**Last Updated:** January 20, 2026  
**Total Resources:** 38 (+4 new 2025-2026 models)  
**Maintained by:** [@ArjunFrancis](https://github.com/ArjunFrancis)

---

â­ **If you found this category helpful, please star the repository!**

[â† Back to Main Repository](../README.md)